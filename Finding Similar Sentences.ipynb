{
 "metadata": {
  "name": "",
  "signature": "sha256:edc22d902f6b29cd33cf16e0ad3e98396efc1fc95c65fb6a0e203acd0864cae5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.misc import comb\n",
      "#!pip install python-Levenshtein\n",
      "import Levenshtein\n",
      "import numpy as np\n",
      "import itertools"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Task"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Task is to quickly find the number of pairs of sentences that are at the word-level edit distance at most 1. Two sentences S1 and S2 they are at edit distance 1 if S1 can be transformed to S2 by: adding, removing or substituting a single word.\n",
      "\n",
      "For example, consider the following sentences where each letter represents a word:\n",
      "* S1: A B C D\n",
      "* S2: A B X D\n",
      "* S3: A B C\n",
      "* S4: A B X C\n",
      "Then pairs the following pairs of sentences are at word edit distance 1 or less: (S1, S2), (S1, S3), (S2, S4), (S3, S4).\n",
      "\n",
      "The input data has 9,397,023 sentences, each one divided by a new line and with the sentence id at the beginning of the line. The zip compressed file size is around 500MB and it's located here.\n",
      "All sentences in the input data are at least 10 words long. A straightforward LSH approach like the one taught in class for jaccard similarity can be used to solve this problem, however it may not necessarily be the faster approach.\n",
      "\n",
      "Submit the number of similar pairs you find as a number without comas. For example, if you find 12,345 pairs, submit 12345.\n",
      "\n",
      "Be creative, share your ideas in the forum, and most importantly, have fun!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def jaccardSim(X, Y):\n",
      "    set1, set2 = set(X), set(Y)\n",
      "    return len(set1.intersection(set2))*1./len(set1.union(set2))\n",
      "\n",
      "a = set([1,2,3,4])\n",
      "b = set([1,2])\n",
      "c = set([1,2,3])\n",
      "\n",
      "print jaccardSim(a,b)\n",
      "print jaccardSim(b,c)\n",
      "print jaccardSim(a,c)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.5\n",
        "0.666666666667\n",
        "0.75\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Hashing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Try using lshhdc library (<a href=https://github.com/go2starr/lshhdc>github</a> or <a href=http://nbviewer.ipython.org/github/fnl/asdm-tm-class/blob/master/Locality%20Sensitive%20Hashing.ipynb>notebook</a>):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import lsh"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sentences contain at least 10 items and need to be within edit distance 1 of each other. Thus their Jaccard similarity must be above 0.9 for edit distance criterion to be possibly true."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lshStore = lsh.Cluster(threshold=.9, width=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hash([\"as\"])   #mutable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "unhashable type: 'list'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-20-3338e2b24bfb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"as\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'list'"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hash((\"as\"))   #immutable"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 24,
       "text": [
        "-1549758574"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Edit distance"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use python-Levenshtein module:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Levenshtein.distance(\"abcde\", \"acfdeg\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "3"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Doesn't work for non-strings:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Levenshtein.distance((_ for _ in \"abcde\"), (_ for _ in \"acfdeg\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "distance expected two Strings or two Unicodes",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-51-f13134f930af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLevenshtein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m\"abcde\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;34m\"acfdeg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: distance expected two Strings or two Unicodes"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Own version for edit distance 1:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def maxDist1(iter1, iter2):\n",
      "    \"\"\"\n",
      "    Not all iterables! - need index lookups (so not a sets for example).\n",
      "    \"\"\"\n",
      "    lengthDiff = len(iter1) - len(iter2)\n",
      "    if lengthDiff ** 2 > 1:\n",
      "        # length difference must be in -1, 0 1\n",
      "        return False\n",
      "    elif lengthDiff < 0:\n",
      "        # make iter1 the longer one \n",
      "        iter1, iter2 = iter2, iter1\n",
      "        if any((iter1[:idx] + iter1[idx + 1:]) == iter2 for idx in xrange(1, len(iter1))):\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "    else:\n",
      "        # same length case - must only differ in one case\n",
      "        if any(iter1[:idx] == iter2[:idx] and iter1[idx+1:] == iter2[idx+1:] for idx in xrange(len(iter1))):\n",
      "            return True\n",
      "        else:\n",
      "            return False\n",
      "    \n",
      "print maxDist1([1,2], [2,3,4])\n",
      "print maxDist1((1,2,3), (1,2,3,4))\n",
      "print maxDist1((1,2,3), (1,2,3,4))\n",
      "print maxDist1([1,2,3],[1,2,4])\n",
      "print maxDist1([1,3,3],[1,2,4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "False\n",
        "True\n",
        "True\n",
        "True\n",
        "False\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "-----------------------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(r\"C:\\Users\\andrewd\\Desktop\\sentences\\sentences.txt\", \"rb\") as f:\n",
      "    for idx, line in enumerate(f):\n",
      "                \n",
      "        if idx > 100000:\n",
      "            break\n",
      "            \n",
      "        lineTuple = tuple(line[2:].split())    #must be immutable\n",
      "        lshStore.add_set(lineTuple)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "totalPairs = 0\n",
      "totalClosePairs= 0\n",
      "checks = []\n",
      "\n",
      "potentials = lshStore.get_sets()\n",
      "for idx, thing in enumerate(potentials):\n",
      "    if len(thing) == 1:\n",
      "        continue\n",
      "    totalPairs += comb(len(thing), 2)\n",
      "    \n",
      "    #check edit distance\n",
      "    for (s1, idx1), (s2, idx2) in itertools.product(zip(thing, xrange(len(thing))), zip(thing, xrange(len(thing)))):\n",
      "        if idx1 >= idx2:\n",
      "            continue\n",
      "        if maxDist1(s1, s2):\n",
      "            totalClosePairs += 1\n",
      "            if np.random.random() > 0.999:\n",
      "                checks.append((s1,s2))\n",
      "\n",
      "print totalClosePairs\n",
      "print totalPairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3697760\n",
        "3931380.0\n"
       ]
      }
     ],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx in xrange(1, 100, 10):\n",
      "    print \" \".join(checks[idx][0])\n",
      "    print \" \".join(checks[idx][1])\n",
      "    print \"*\" * 100"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7371 el gobierno no quiere dar soluciones pol ticas al tema ind gena\n",
        "7316 el gobierno no quiere dar soluciones pol ticas al tema ind gena\n",
        "****************************************************************************************************\n",
        "4485 however she was still 15 and was not equipped to make medical decisions on her own whether she was living with the father of her child or not\n",
        "6387 however she was still 15 and was not equipped to make medical decisions on her own whether she was living with the father of her child or not\n",
        "****************************************************************************************************\n",
        "5873 i am the last born of a big family and also a twin my parents were in the navy so we traveled around a bit and then decided to settle in georgia no i am not a peach per se but\n",
        "5881 i am the last born of a big family and also a twin my parents were in the navy so we traveled around a bit and then decided to settle in georgia no i am not a peach per se but\n",
        "****************************************************************************************************\n",
        "152 addressing both the challenges and significant opportunities that humanity is facing requires significant innovation in technology business and building and we are extremely excited to hear mr gores timely exploration of the intersection of these industries\n",
        "3396 addressing both the challenges and significant opportunities that humanity is facing requires significant innovation in technology business and building and we are extremely excited to hear mr gores timely exploration of the intersection of these industries\n",
        "****************************************************************************************************\n",
        "8742 although congress has taken a number of steps to help alleviate the current housing crisis we need to proactively put practices in place that will help prevent another crisis down the road\n",
        "7065 although congress has taken a number of steps to help alleviate the current housing crisis we need to proactively put practices in place that will help prevent another crisis down the road\n",
        "****************************************************************************************************\n",
        "1671 this is an issue of having community leaders come to an agreement\n",
        "1463 this is an issue of having community leaders come to an agreement\n",
        "****************************************************************************************************\n",
        "006 if somebody had a crime that the president had committed that would be a different story\n",
        "074 if somebody had a crime that the president had committed that would be a different story\n",
        "****************************************************************************************************\n",
        "055 if somebody had a crime that the president had committed that would be a different story\n",
        "9777 if somebody had a crime that the president had committed that would be a different story\n",
        "****************************************************************************************************\n",
        "0241 if somebody had a crime that the president had committed that would be a different story\n",
        "4029 if somebody had a crime that the president had committed that would be a different story\n",
        "****************************************************************************************************\n",
        "4941 i am pleased to be part of an effort to bring together the best ideas of both parties and am anxious to move our country forward with balanced legislation that makes us more secure\n",
        "7690 i am pleased to be part of an effort to bring together the best ideas of both parties and am anxious to move our country forward with balanced legislation that makes us more secure\n",
        "****************************************************************************************************\n"
       ]
      }
     ],
     "prompt_number": 97
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Conclusion:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Minhashing method works but is too slow. More scalable method required has the first and second half of each sentence."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---------------------------------------------------------------------"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!pip install mmh3\n",
      "import mmh3\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mmh3.hash(\"asdfajs;ldg\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "-1201308126"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%timeit\n",
      "sentences = {}\n",
      "buckets = defaultdict(set)\n",
      "with open(r\"C:\\Users\\andrewd\\Desktop\\sentences\\sentences.txt\", \"rb\") as f:\n",
      "    for idx, line in enumerate(f):\n",
      "        \n",
      "        sentence = line.split()[1:]   \n",
      "        \n",
      "        sentences[idx] = tuple(sentence)\n",
      "\n",
      "        n = len(sentence)\n",
      "\n",
      "        buckets[hash(tuple(sentence[:n/2]))].add(idx)\n",
      "        buckets[hash(tuple(sentence[(n + 1)/2:]))].add(idx)   \n",
      "            \n",
      "        if idx > 1000000:\n",
      "            break"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%%timeit\n",
      "pairs = 0\n",
      "checks= []\n",
      "seenPairs = set()\n",
      "\n",
      "for key, idList in buckets.iteritems():\n",
      "    if len(idList) < 2:\n",
      "        continue\n",
      "    else:        \n",
      "        bucketSentences= [(sentences[sid], sid) for sid in idList]\n",
      "        data = set((sent, sid, bucketSentences.count((sent, sid))) for (sent, sid) in bucketSentences)\n",
      "\n",
      "        for (s1, sid1, c1), (s2, sid2, c2) in itertools.product(data, data):\n",
      "            if sid1 >= sid2:\n",
      "                continue\n",
      "            if maxDist1(s1, s2):\n",
      "                if (sid1, sid2) in seenPairs:\n",
      "                    continue\n",
      "                else:\n",
      "                    pairs += c1 * c2\n",
      "                    seenPairs.add((sid1, sid2))\n",
      "        \n",
      "        #add in exact matches which appear twice, hence the factor\n",
      "        pairs += sum((c*(c-1))/2 for s, sid, c in data)/2.\n",
      "\n",
      "print pairs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\n",
        "  File \"C:\\Users\\andrewd\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 776, in structured_traceback\n",
        "    records = _fixed_getinnerframes(etb, context, tb_offset)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"C:\\Users\\andrewd\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 230, in wrapped\n",
        "    return f(*args, **kwargs)\n",
        "  File \"C:\\Users\\andrewd\\AppData\\Local\\Continuum\\Anaconda\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 259, in _fixed_getinnerframes\n",
        "    records  = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
        "  File \"C:\\Users\\andrewd\\AppData\\Local\\Continuum\\Anaconda\\lib\\inspect.py\", line 1044, in getinnerframes\n",
        "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Internal Python error in the inspect module.\n",
        "Below is the traceback from this internal error.\n",
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"C:\\Users\\andrewd\\AppData\\Local\\Continuum\\Anaconda\\lib\\inspect.py\", line 1004, in getframeinfo\n",
        "    filename = getsourcefile(frame) or getfile(frame)\n",
        "  File \"C:\\Users\\andrewd\\AppData\\Local\\Continuum\\Anaconda\\lib\\inspect.py\", line 454, in getsourcefile\n",
        "    if hasattr(getmodule(object, filename), '__loader__'):\n",
        "  File \"C:\\Users\\andrewd\\AppData\\Local\\Continuum\\Anaconda\\lib\\inspect.py\", line 491, in getmodule\n",
        "    if ismodule(module) and hasattr(module, '__file__'):\n",
        "KeyboardInterrupt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Unfortunately, your original traceback can not be constructed.\n",
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": ""
      }
     ],
     "prompt_number": 128
    }
   ],
   "metadata": {}
  }
 ]
}